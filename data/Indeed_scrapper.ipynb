{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy\n",
    "from scrapy.crawler import CrawlerProcess\n",
    "from scrapy.selector import HtmlXPathSelector\n",
    "from scrapy.linkextractors import LinkExtractor\n",
    "from scrapy.spiders import Rule, CrawlSpider\n",
    "import logging\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JobItem(scrapy.Item):\n",
    "    joburl = scrapy.Field()\n",
    "    title = scrapy.Field()\n",
    "    desc = scrapy.Field()\n",
    "    salary = scrapy.Field()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IndeedScrapping(scrapy.Spider):\n",
    "    name = \"IndeedScrapping\"\n",
    "    \n",
    "    allowed_domains = [\"indeed.com\"]\n",
    "    \n",
    "    start_urls = [\n",
    "        'https://www.indeed.com/jobs?q=software+engineer&l=Boston%2C+MA',\n",
    "    ]\n",
    "    \n",
    "    rules = [\n",
    "        Rule(\n",
    "            LinkExtractor(\n",
    "                canonicalize=True,\n",
    "                unique=True\n",
    "            ),\n",
    "            follow=True,\n",
    "            callback=\"parse_next_site\"\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    custom_settings = {\n",
    "        'LOG_LEVEL': logging.WARNING,\n",
    "        'DEPTH_LIMIT': 1,\n",
    "        'FEED_FORMAT':'json',\n",
    "        'FEED_URI': 'indeed_jobs.json',\n",
    "    }\n",
    "    \n",
    "    def start_requests(self):\n",
    "        for url in self.start_urls:\n",
    "            yield scrapy.Request(url, callback=self.parse, dont_filter=True)\n",
    "\n",
    "    def parse_next_site(self, response):\n",
    "        item = response.meta['item']\n",
    "        for job in response.css('div.jobsearch-JobComponent'):\n",
    "            item['title'] = job.css('div.jobsearch-DesktopStickyContainer > h3.jobsearch-JobInfoHeader-title::text').get()\n",
    "            desc = job.css('div.jobsearch-JobComponent-description').get()\n",
    "            item['desc'] = cleantext = BeautifulSoup(desc, \"lxml\").text\n",
    "            item['salary'] = job.css('span.icl-u-xs-mr--xs::text').get()\n",
    "        yield item\n",
    "\n",
    "    def parse(self, response):\n",
    "        items=[]\n",
    "        for job in response.css('div.jobsearch-SerpJobCard'):\n",
    "            item = JobItem()\n",
    "\n",
    "            url = job.css('a::attr(\"href\")').get()\n",
    "            if url is not None:\n",
    "                url = response.urljoin(url)\n",
    "                item['joburl'] = url\n",
    "                request = scrapy.Request(url, callback=self.parse_next_site, dont_filter=True)\n",
    "                request.meta['item'] = item\n",
    "                yield request\n",
    "#         yield{'software_engineer': request.meta['item']}\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "process = CrawlerProcess()\n",
    "process.crawl(IndeedScrapping)\n",
    "process.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
